{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a52523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9e5c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 2\n",
    "some_digit = X[0].reshape(8, 8)\n",
    "plt.imshow(some_digit, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5ae3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of the first instance: 0\n"
     ]
    }
   ],
   "source": [
    "# Task 3\n",
    "print(f\"Label of the first instance: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18376f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20145815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('svm', SVC(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fec201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9860820953265242\n",
      "Best Parameters: {'svm__C': 8, 'svm__kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Task 6\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'svm__C': [1, 5, 8, 10], 'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params, cv=4, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff2e65",
   "metadata": {},
   "source": [
    "Best Score: 0.9861\n",
    "\n",
    "The best cross-validated accuracy achieved on the training set is approximately 98.61%. This indicates that the SVM model, with the selected hyperparameters, performs exceptionally well on the training data.\n",
    "Best Parameters:\n",
    "\n",
    "C (Regularization Parameter): 8\n",
    "The regularization parameter (C) determines the trade-off between achieving a smooth decision boundary and classifying training points correctly. A higher C emphasizes classifying points correctly, potentially leading to a more complex decision boundary.\n",
    "Kernel Function: 'poly'\n",
    "The polynomial kernel has been chosen as the best kernel function. This indicates that, according to the cross-validation results, a polynomial kernel provides the optimal balance between capturing complex relationships in the data and preventing overfitting.\n",
    "Analysis:\n",
    "\n",
    "High Accuracy:\n",
    "\n",
    "The high cross-validated accuracy score (98.61%) suggests that the model generalizes well on the training set. However, it's crucial to assess its performance on unseen data.\n",
    "Optimal Hyperparameters:\n",
    "\n",
    "The choice of a polynomial kernel with a regularization parameter (C) of 8 indicates that the model should be flexible enough to capture complex patterns in the data while avoiding overfitting.\n",
    "Consideration for Further Evaluation:\n",
    "\n",
    "While the model shows excellent performance on the training set, it's essential to evaluate it on the test set to ensure its generalization to new, unseen data.\n",
    "In conclusion, the grid search has identified hyperparameters that yield a highly accurate SVM model on the training data. The next step would be to evaluate this model on the test set to assess its real-world performance and generalization capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec2e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Explained by Each Component:\n",
      "[0.12164624 0.09634853 0.08578334 0.06457027 0.04897962 0.04183235\n",
      " 0.03929765 0.03282099 0.02979124 0.02809632 0.02741238 0.02602094\n",
      " 0.02304403 0.02207157 0.02049244 0.01784251 0.01735509 0.01662399\n",
      " 0.01624181 0.01510787 0.01347544 0.01294908 0.0117134  0.01062522\n",
      " 0.01039421 0.00941729 0.00932626 0.00840604 0.00827709 0.00789892\n",
      " 0.00749741 0.00715596 0.00665508 0.00641068 0.00594299 0.00567498\n",
      " 0.00514703 0.00473037 0.00454567 0.00420127]\n",
      "Number of Components: 40\n"
     ]
    }
   ],
   "source": [
    "# Task 7\n",
    "best_estimator = grid_search.best_estimator_\n",
    "pca_variance_ratios = best_estimator.named_steps['pca'].explained_variance_ratio_\n",
    "print(\"Variance Explained by Each Component:\")\n",
    "print(pca_variance_ratios)\n",
    "print(f\"Number of Components: {len(pca_variance_ratios)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aeccc9",
   "metadata": {},
   "source": [
    "Variance Explained by Each Component:\n",
    "\n",
    "The list represents the variance explained by each principal component after applying Principal Component Analysis (PCA). Additionally, the total number of components selected by PCA is 40.\n",
    "\n",
    "Analysis:\n",
    "\n",
    "Cumulative Variance:\n",
    "\n",
    "The cumulative variance explained by the components is a crucial metric. By summing up the explained variances from the first component to the last, we can assess how much of the total variance in the original data is retained. In this case, you might want to check the cumulative variance to understand how well the selected 40 components capture the overall variability.\n",
    "Individual Component Contribution:\n",
    "\n",
    "Each value in the list indicates the proportion of variance explained by a single principal component. Higher values suggest that the corresponding component retains more information from the original dataset.\n",
    "Number of Components:\n",
    "\n",
    "The choice of 40 components is a balance between dimensionality reduction and retaining sufficient information. The explained variance plot is often used to determine the optimal number of components. It shows the diminishing returns in terms of variance explained as you include more components.\n",
    "Dimensionality Reduction:\n",
    "\n",
    "The goal of PCA is often to reduce the dimensionality of the data while retaining as much information as possible. With 40 components, you've significantly reduced the feature space from the original 64 features. This can be beneficial for training models more efficiently and mitigating the curse of dimensionality.\n",
    "Interpretability:\n",
    "\n",
    "Each principal component is a linear combination of the original features. While they may not have a direct interpretation like the original features, you can investigate which original features contribute most to each principal component. This can provide insights into the underlying structure of the data.\n",
    "In conclusion, PCA with 40 components retains a substantial amount of variance from the original dataset, enabling effective dimensionality reduction. The choice of the number of components should be guided by a trade-off between reducing dimensionality and maintaining sufficient information for the specific task or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d124e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Task 8\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5876f1",
   "metadata": {},
   "source": [
    "The accuracy achieved on the test set is 0.9833, which translates to 98.33%. Here's an analysis of the result:\n",
    "\n",
    "High Accuracy:\n",
    "\n",
    "An accuracy of 98.33% is exceptionally high and indicates that the model performs very well on the unseen test data. This suggests that the model has successfully generalized from the training data to make accurate predictions on new, previously unseen instances.\n",
    "Reliable Generalization:\n",
    "\n",
    "The high accuracy on the test set demonstrates the robustness of the model. It has learned patterns from the training data that are applicable to new, similar instances. This reliability in generalization is a key indicator of a well-performing model.\n",
    "Effective Feature Representation:\n",
    "\n",
    "PCA, by reducing the dimensionality of the data while retaining important information, seems to have created an effective feature representation. The reduced feature set derived from PCA is able to capture the essential patterns for distinguishing between different digits.\n",
    "Applicability to Real-World Scenarios:\n",
    "\n",
    "In tasks like digit recognition, achieving a high accuracy on the test set is crucial for real-world applications. A model with such high accuracy can be considered reliable for deployment in scenarios where automated digit recognition is required.\n",
    "Potential for Further Analysis:\n",
    "\n",
    "While accuracy is a fundamental metric, it's also valuable to explore other metrics like precision, recall, and F1 score, especially in situations where imbalances exist between the classes. Additionally, visually inspecting misclassified instances or exploring a confusion matrix can provide insights into the model's specific strengths and weaknesses.\n",
    "Consideration of Business Requirements:\n",
    "\n",
    "The choice of metrics and the acceptable level of accuracy depends on the specific requirements of the application. In some cases, extremely high accuracy may be critical, while in others, the emphasis might be on minimizing false positives or false negatives.\n",
    "In summary, the achieved accuracy of 98.33% on the test set indicates a well-performing model, and further analysis, as well as consideration of specific business needs, can provide a more comprehensive understanding of its strengths and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
